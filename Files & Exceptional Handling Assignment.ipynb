{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN4dcRBMXsdG"
   },
   "source": [
    "1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where multiprocessing is a better choice.\n",
    "\n",
    "Answer 1:\n",
    "\n",
    "When to Use Multithreading:\n",
    "\n",
    "1. I/O-Bound Tasks:\n",
    "   - Description: Multithreading is    well-suited for tasks where the bottleneck is I/O operations, such as file reading/writing, network communication, or database queries.\n",
    "\n",
    "   - Reason: Threads can efficiently manage I/O-bound operations by allowing one thread to handle I/O while others continue processing. This can lead to better resource utilization and improved responsiveness.\n",
    "\n",
    "2. Shared Memory and Lightweight Context\n",
    "   Switching:\n",
    "   - Description: If your tasks require frequent data sharing and communication, threads are beneficial because they share the same memory space.\n",
    "\n",
    "   - Reason: Threads can access shared data without the overhead of inter-process communication (IPC) mechanisms used in multiprocessing. Context switching between threads is generally faster than between processes.\n",
    "\n",
    "3. Low Computational Overhead:\n",
    "   - Description: When the computational tasks are relatively light and the system has multiple cores, but the tasks need to be handled concurrently, threads are a good choice.\n",
    "\n",
    "   - Reason: The overhead of creating and managing threads is typically less than that of processes, making threads suitable for situations where the computational load is not very high but concurrency is needed.\n",
    "\n",
    "4. User Interface Applications:\n",
    "   - Description: For applications with graphical user interfaces (GUIs), such as desktop applications, multithreading is often used to keep the interface responsive while performing background operations.\n",
    "\n",
    "   - Reason: Threads can handle background tasks while the main thread continues to update the GUI and handle user interactions.\n",
    "\n",
    "When to Use Multiprocessing:\n",
    "\n",
    "1. CPU-Bound Tasks:\n",
    "   - Description: For tasks that are computationally intensive and require significant processing power, multiprocessing is preferable.\n",
    "\n",
    "   - Reason: Multiprocessing allows tasks to run in separate processes, each with its own Python interpreter and memory space. This is particularly useful in Python due to the Global Interpreter Lock (GIL), which can limit the effectiveness of multithreading for CPU-bound operations.\n",
    "\n",
    "2. Isolation and Stability:\n",
    "   - Description: When you need process isolation to ensure that a failure in one task does not affect others, multiprocessing is beneficial.\n",
    "\n",
    "   - Reason: Processes do not share memory space, so a crash or error in one process doesn’t directly impact others. This isolation can lead to more stable applications in certain scenarios.\n",
    "\n",
    "3. Parallel Execution Across Multiple Cores:\n",
    "   - Description: If you want to take full advantage of multiple CPU cores for heavy computations, multiprocessing is a better fit.\n",
    "\n",
    "   - Reason: Each process can run on a separate core, bypassing the GIL and making it possible to execute multiple CPU-bound tasks in true parallel.\n",
    "\n",
    "4. Memory and Resource Management:\n",
    "   - Description: When different tasks require independent memory and resources, multiprocessing helps manage these resources more effectively.\n",
    "\n",
    "   - Reason: Processes have separate memory spaces, which can help prevent issues like memory leaks from affecting other tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R0XJ6TeveRfQ"
   },
   "source": [
    "2. Describe what a process pool is and how it helps in managing multiple processes efficiently.\n",
    "\n",
    "Answer 2:\n",
    "\n",
    "A **process pool** is a collection of worker processes managed by a pool manager, which is used to execute tasks concurrently. This concept is particularly useful in managing and optimizing the execution of multiple processes efficiently. Here's a detailed explanation of what a process pool is and how it helps:\n",
    "\n",
    "### What is a Process Pool?\n",
    "\n",
    "A process pool is essentially a pool of pre-created processes that are kept alive and ready to execute tasks. When you need to perform a task, instead of creating a new process each time (which can be expensive in terms of time and system resources), you submit the task to the process pool. The pool manager assigns the task to an available worker process from the pool.\n",
    "\n",
    "### Key Components of a Process Pool\n",
    "\n",
    "1. **Pool Manager:** The component responsible for managing the worker processes. It handles tasks like creating processes, assigning tasks, and managing the lifecycle of the processes.\n",
    "\n",
    "2. **Worker Processes:** The individual processes in the pool that execute the tasks. Each worker process operates independently and can handle tasks concurrently.\n",
    "\n",
    "3. **Task Queue:** A queue where tasks are placed to be picked up by available worker processes. This queue helps in managing and organizing the tasks that need to be executed.\n",
    "\n",
    "### How a Process Pool Helps in Managing Multiple Processes Efficiently\n",
    "\n",
    "1. **Reduced Overhead:**\n",
    "   - **Description:** Creating and destroying processes can be resource-intensive and time-consuming. A process pool minimizes this overhead by reusing existing processes.\n",
    "   - **Benefit:** This leads to faster task execution and reduced system resource consumption, as the cost of creating and terminating processes is avoided.\n",
    "\n",
    "2. **Concurrency Management:**\n",
    "   - **Description:** The process pool allows multiple tasks to be executed concurrently by different worker processes.\n",
    "   - **Benefit:** This maximizes CPU utilization and improves the efficiency of handling multiple tasks, especially when dealing with large numbers of tasks or heavy computations.\n",
    "\n",
    "3. **Resource Limiting:**\n",
    "   - **Description:** You can configure the process pool to limit the number of concurrent processes. This helps in controlling resource usage and preventing overloading the system.\n",
    "   - **Benefit:** It ensures that the system resources are not exhausted and that the performance remains stable even under heavy load.\n",
    "\n",
    "4. **Task Scheduling:**\n",
    "   - **Description:** Tasks are managed in a queue and assigned to available worker processes based on their availability.\n",
    "   - **Benefit:** This leads to balanced workload distribution and ensures that tasks are executed in an orderly and efficient manner.\n",
    "\n",
    "5. **Improved Scalability:**\n",
    "   - **Description:** By adjusting the size of the process pool, you can scale the concurrency to match the workload.\n",
    "   - **Benefit:** This allows the system to handle varying amounts of work efficiently, adapting to different levels of demand.\n",
    "\n",
    "6. **Error Handling and Recovery:**\n",
    "   - **Description:** The pool manager can handle errors and restart failed worker processes.\n",
    "   - **Benefit:** This increases the robustness and reliability of the system, ensuring that errors in one process do not disrupt the overall task execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1552,
     "status": "ok",
     "timestamp": 1726064921025,
     "user": {
      "displayName": "Shazil Parwez",
      "userId": "17294264299167245854"
     },
     "user_tz": -330
    },
    "id": "hEUjwCtee8xu",
    "outputId": "7cd40d19-5aae-4560-db59-d20217884663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16, 25]\n"
     ]
    }
   ],
   "source": [
    "#Example:\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    numbers = [1, 2, 3, 4, 5]\n",
    "    with Pool(processes=4) as pool:\n",
    "        results = pool.map(square, numbers)\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09HOasYefoLf"
   },
   "source": [
    "3. Explain what multiprocessing is and why it is used in Python programs.\n",
    "\n",
    "Answer 3:\n",
    "\n",
    "**Multiprocessing** refers to a programming paradigm that involves running multiple processes simultaneously. This can be particularly useful for improving the performance and responsiveness of programs that perform heavy computations or handle multiple tasks concurrently. Here’s a detailed explanation of what multiprocessing is and why it is used in Python programs:\n",
    "\n",
    "### What is Multiprocessing?\n",
    "\n",
    "**Multiprocessing** is the technique of executing multiple processes in parallel. Each process runs independently and has its own memory space, resources, and execution environment. Processes can run on separate CPU cores, allowing for true parallelism.\n",
    "\n",
    "### Key Concepts of Multiprocessing:\n",
    "\n",
    "1. **Process:**\n",
    "   - A process is an instance of a program that runs independently with its own memory space. Processes do not share memory, which makes them more isolated compared to threads.\n",
    "\n",
    "2. **Concurrency vs. Parallelism:**\n",
    "   - **Concurrency:** Multiple processes or threads are making progress within overlapping time periods.\n",
    "   - **Parallelism:** Multiple processes or threads are executed simultaneously on different CPU cores.\n",
    "\n",
    "3. **Inter-Process Communication (IPC):**\n",
    "   - Since processes have separate memory spaces, they need mechanisms to communicate and share data. IPC methods include pipes, queues, and shared memory.\n",
    "\n",
    "### Why is Multiprocessing Used in Python Programs?\n",
    "\n",
    "Python’s Global Interpreter Lock (GIL) is a significant factor in why multiprocessing is used. Here’s a detailed explanation:\n",
    "\n",
    "1. **Global Interpreter Lock (GIL):**\n",
    "   - **Description:** Python’s GIL is a mutex that protects access to Python objects, preventing multiple threads from executing Python bytecodes simultaneously in a single process. This is necessary to ensure thread safety in a language that is not inherently thread-safe.\n",
    "   - **Impact:** The GIL can be a bottleneck in CPU-bound multi-threaded programs, as it limits the effective use of multiple CPU cores.\n",
    "\n",
    "2. **True Parallelism:**\n",
    "   - **Description:** Multiprocessing allows Python programs to bypass the GIL by running separate processes. Each process has its own Python interpreter and memory space, so they can run on separate CPU cores and execute tasks in true parallel.\n",
    "   - **Benefit:** This is especially useful for CPU-bound tasks that require significant processing power and can be split into independent units of work.\n",
    "\n",
    "3. **Handling CPU-Bound Tasks:**\n",
    "   - **Description:** For tasks that require intense computation and can benefit from parallel execution, multiprocessing provides a way to utilize multiple cores effectively.\n",
    "   - **Benefit:** By dividing the work among multiple processes, you can achieve faster execution and better performance for computationally heavy tasks.\n",
    "\n",
    "4. **Isolation and Stability:**\n",
    "   - **Description:** Each process in a multiprocessing environment is isolated from the others, which helps in handling errors and crashes.\n",
    "   - **Benefit:** A failure in one process does not affect other processes, making the application more robust and stable.\n",
    "\n",
    "5. **Avoiding Thread Safety Issues:**\n",
    "   - **Description:** Multiprocessing avoids the complexities of thread synchronization and shared memory issues that are inherent in multithreading.\n",
    "   - **Benefit:** Processes do not share memory, so there’s no need to manage thread-safe operations for shared data, simplifying the development and reducing the risk of bugs related to concurrency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1726065533854,
     "user": {
      "displayName": "Shazil Parwez",
      "userId": "17294264299167245854"
     },
     "user_tz": -330
    },
    "id": "eMv0IDVDf09R",
    "outputId": "7386e926-4d66-4084-87f2-245c86410876"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker 0 started by process Process-55\n",
      "Worker 1 started by process Process-56\n",
      "Worker 2 started by process Process-57\n",
      "Worker 3 started by process Process-58\n",
      "Worker 4 started by process Process-59\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, current_process\n",
    "\n",
    "def worker(num):\n",
    "    print(f'Worker {num} started by process {current_process().name}')\n",
    "\n",
    "if __name__     == '__main__':\n",
    "    processes = []\n",
    "    for i in range(5):\n",
    "        p = Process(target=worker, args=(i,))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2285,
     "status": "ok",
     "timestamp": 1726065796394,
     "user": {
      "displayName": "Shazil Parwez",
      "userId": "17294264299167245854"
     },
     "user_tz": -330
    },
    "id": "vB4uKXv-gqTO",
    "outputId": "e0829784-3331-4c78-8323-432eb9b3e758"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 0: [0]\n",
      "Added 1: [0, 1]\n",
      "Removed 0: [1]\n",
      "Added 2: [1, 2]\n",
      "Removed 1: [2]\n",
      "Added 3: [2, 3]\n",
      "Added 4: [2, 3, 4]\n",
      "Removed 2: [3, 4]\n",
      "Added 5: [3, 4, 5]\n",
      "Added 6: [3, 4, 5, 6]\n",
      "Removed 3: [4, 5, 6]\n",
      "Added 7: [4, 5, 6, 7]\n",
      "Added 8: [4, 5, 6, 7, 8]\n",
      "Removed 4: [5, 6, 7, 8]\n",
      "Added 9: [5, 6, 7, 8, 9]\n",
      "Removed 5: [6, 7, 8, 9]\n",
      "Removed 6: [7, 8, 9]\n",
      "Removed 7: [8, 9]\n",
      "Removed 8: [9]\n",
      "Removed 9: []\n",
      "Final shared list: []\n"
     ]
    }
   ],
   "source": [
    "# 4. Write a Python program using multithreading where one thread adds numbers to a list, and another thread removes numbers from the list. Implement a mechanism to avoid race conditions using threading.Lock.\n",
    "\n",
    "#Answer 4:\n",
    "\n",
    "import threading\n",
    "import time\n",
    "shared_list = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "def adder():\n",
    "    for i in range(10):\n",
    "        time.sleep(0.1)\n",
    "        with lock:\n",
    "            shared_list.append(i)\n",
    "            print(f\"Added {i}: {shared_list}\")\n",
    "\n",
    "def remover():\n",
    "    for _ in range(10):\n",
    "        time.sleep(0.2)\n",
    "        with lock:\n",
    "            if shared_list:\n",
    "                removed_value = shared_list.pop(0)\n",
    "                print(f\"Removed {removed_value}: {shared_list}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    add_thread = threading.Thread(target=adder, name='AdderThread')\n",
    "    remove_thread = threading.Thread(target=remover, name='RemoverThread')\n",
    "    add_thread.start()\n",
    "    remove_thread.start()\n",
    "    add_thread.join()\n",
    "    remove_thread.join()\n",
    "\n",
    "    print(\"Final shared list:\", shared_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzDPaPIUiwhT"
   },
   "source": [
    "5. Describe the methods and tools available in Python for safely sharing data between threads and\n",
    "processes.\n",
    "\n",
    "Answer 5:\n",
    "\n",
    "In Python, sharing data between threads and processes requires careful management to ensure that data integrity is maintained and that race conditions are avoided. Python provides various methods and tools for safely sharing data in multithreaded and multiprocessing environments. Here’s an overview:\n",
    "\n",
    "### Sharing Data Between Threads\n",
    "\n",
    "When working with threads, you need to ensure that shared data is accessed in a thread-safe manner. Here are some methods and tools available:\n",
    "\n",
    "1. **Threading Locks:**\n",
    "   - **Description:** A `threading.Lock` (or simply `Lock`) is used to synchronize access to shared resources. Only one thread can hold the lock at a time, ensuring exclusive access to the shared data.\n",
    "   - **Usage Example:**\n",
    "     ```python\n",
    "     import threading\n",
    "\n",
    "     shared_data = []\n",
    "     lock = threading.Lock()\n",
    "\n",
    "     def thread_function():\n",
    "         with lock:\n",
    "             # Access or modify shared_data safely\n",
    "             shared_data.append(1)\n",
    "     ```\n",
    "\n",
    "2. **Threading RLocks:**\n",
    "   - **Description:** A `threading.RLock` (reentrant lock) allows a thread to acquire the same lock multiple times without causing a deadlock. Useful in cases where the same thread may need to enter a critical section multiple times.\n",
    "   - **Usage Example:**\n",
    "     ```python\n",
    "     import threading\n",
    "\n",
    "     rlock = threading.RLock()\n",
    "\n",
    "     def thread_function():\n",
    "         with rlock:\n",
    "             # Critical section\n",
    "             with rlock:\n",
    "                 # Nested critical section\n",
    "                 pass\n",
    "     ```\n",
    "\n",
    "3. **Condition Variables:**\n",
    "   - **Description:** `threading.Condition` allows threads to wait for certain conditions to be met before continuing execution. It can be used to coordinate thread execution based on specific conditions.\n",
    "   - **Usage Example:**\n",
    "     ```python\n",
    "     import threading\n",
    "\n",
    "     condition = threading.Condition()\n",
    "     shared_data = []\n",
    "\n",
    "     def producer():\n",
    "         with condition:\n",
    "             shared_data.append(1)\n",
    "             condition.notify()  # Notify waiting threads\n",
    "\n",
    "     def consumer():\n",
    "         with condition:\n",
    "             condition.wait()  # Wait for notification\n",
    "             item = shared_data.pop()\n",
    "     ```\n",
    "\n",
    "4. **Events:**\n",
    "   - **Description:** `threading.Event` allows threads to signal one another. One thread can set an event, and other threads can wait for the event to be set before proceeding.\n",
    "   - **Usage Example:**\n",
    "     ```python\n",
    "     import threading\n",
    "\n",
    "     event = threading.Event()\n",
    "\n",
    "     def thread_function():\n",
    "         event.wait()  # Wait until the event is set\n",
    "         # Continue execution\n",
    "\n",
    "     def signal_function():\n",
    "         # Set the event to signal other threads\n",
    "         event.set()\n",
    "     ```\n",
    "\n",
    "### Sharing Data Between Processes\n",
    "\n",
    "When working with multiple processes, you must use inter-process communication (IPC) mechanisms because processes have separate memory spaces. Python provides several tools for safely sharing data between processes:\n",
    "\n",
    "1. **Multiprocessing Locks:**\n",
    "   - **Description:** `multiprocessing.Lock` provides a way to synchronize access to shared resources among processes, similar to `threading.Lock`.\n",
    "   - **Usage Example:**\n",
    "     ```python\n",
    "     from multiprocessing import Lock\n",
    "\n",
    "     lock = Lock()\n",
    "\n",
    "     def process_function():\n",
    "         with lock:\n",
    "             # Access or modify shared resource\n",
    "             pass\n",
    "     ```\n",
    "\n",
    "2. **Multiprocessing Queues:**\n",
    "   - **Description:** `multiprocessing.Queue` is a thread- and process-safe FIFO queue that allows processes to send and receive data.\n",
    "   - **Usage Example:**\n",
    "     ```python\n",
    "     from multiprocessing import Process, Queue\n",
    "\n",
    "     def producer(queue):\n",
    "         queue.put('data')\n",
    "\n",
    "     def consumer(queue):\n",
    "         data = queue.get()\n",
    "         print(data)\n",
    "\n",
    "     if __name__ == '__main__':\n",
    "         queue = Queue()\n",
    "         p1 = Process(target=producer, args=(queue,))\n",
    "         p2 = Process(target=consumer, args=(queue,))\n",
    "         p1.start()\n",
    "         p2.start()\n",
    "         p1.join()\n",
    "         p2.join()\n",
    "     ```\n",
    "\n",
    "3. **Multiprocessing Pipes:**\n",
    "   - **Description:** `multiprocessing.Pipe` provides a way to send data between processes using a pair of connection objects.\n",
    "   - **Usage Example:**\n",
    "     ```python\n",
    "     from multiprocessing import Process, Pipe\n",
    "\n",
    "     def sender(conn):\n",
    "         conn.send('message')\n",
    "         conn.close()\n",
    "\n",
    "     def receiver(conn):\n",
    "         msg = conn.recv()\n",
    "         print(msg)\n",
    "         conn.close()\n",
    "\n",
    "     if __name__ == '__main__':\n",
    "         parent_conn, child_conn = Pipe()\n",
    "         p1 = Process(target=sender, args=(child_conn,))\n",
    "         p2 = Process(target=receiver, args=(parent_conn,))\n",
    "         p1.start()\n",
    "         p2.start()\n",
    "         p1.join()\n",
    "         p2.join()\n",
    "     ```\n",
    "\n",
    "4. **Shared Memory:**\n",
    "   - **Description:** `multiprocessing.Value` and `multiprocessing.Array` provide a way to share data directly in memory between processes.\n",
    "   - **Usage Example:**\n",
    "     ```python\n",
    "     from multiprocessing import Process, Value, Array\n",
    "\n",
    "     def increment(shared_value):\n",
    "         for _ in range(100):\n",
    "             with shared_value.get_lock():\n",
    "                 shared_value.value += 1\n",
    "\n",
    "     if __name__ == '__main__':\n",
    "         shared_value = Value('i', 0)\n",
    "         processes = [Process(target=increment, args=(shared_value,)) for _ in range(4)]\n",
    "\n",
    "         for p in processes:\n",
    "             p.start()\n",
    "         for p in processes:\n",
    "             p.join()\n",
    "\n",
    "         print(shared_value.value)\n",
    "     ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZF-koVjjgri"
   },
   "source": [
    "6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for doing so.\n",
    "\n",
    "Answer 6:\n",
    "\n",
    "Handling exceptions in concurrent programs is crucial for several reasons, including ensuring program stability, maintaining data integrity, and facilitating debugging. Concurrent programs, which involve multiple threads or processes running simultaneously, can introduce complexities that make exception handling more challenging compared to single-threaded programs.\n",
    "\n",
    "### Why Exception Handling is Crucial in Concurrent Programs\n",
    "\n",
    "1. **Program Stability:**\n",
    "   - **Description:** Exceptions in concurrent programs can cause unexpected terminations of threads or processes, potentially leading to incomplete or inconsistent states.\n",
    "   - **Importance:** Properly handling exceptions ensures that your program can recover gracefully from errors or at least shut down cleanly.\n",
    "\n",
    "2. **Data Integrity:**\n",
    "   - **Description:** Concurrent operations can lead to race conditions or corrupted data if exceptions are not handled properly.\n",
    "   - **Importance:** Handling exceptions helps ensure that shared resources are left in a consistent state and that operations are not interrupted in a way that corrupts data.\n",
    "\n",
    "3. **Resource Management:**\n",
    "   - **Description:** Unhandled exceptions can lead to resource leaks, such as unclosed files or unreleased locks.\n",
    "   - **Importance:** Proper exception handling ensures that resources are released appropriately, even if an error occurs.\n",
    "\n",
    "4. **Debugging and Maintenance:**\n",
    "   - **Description:** Exception handling provides mechanisms to log errors and provide meaningful error messages.\n",
    "   - **Importance:** This aids in debugging and maintenance by making it easier to trace and understand the source of problems.\n",
    "\n",
    "### Techniques for Handling Exceptions in Concurrent Programs\n",
    "\n",
    "1. **Exception Handling in Threads:**\n",
    "   - **Try-Except Blocks:** Use try-except blocks within the thread's target function to catch and handle exceptions.\n",
    "     ```python\n",
    "     import threading\n",
    "\n",
    "     def thread_function():\n",
    "         try:\n",
    "             pass\n",
    "         except Exception as e:\n",
    "             print(f\"Exception in thread: {e}\")\n",
    "\n",
    "     thread = threading.Thread(target=thread_function)\n",
    "     thread.start()\n",
    "     thread.join()\n",
    "     ```\n",
    "\n",
    "   - **Thread Communication:** Use thread-safe queues or other communication mechanisms to report exceptions back to the main thread or another monitoring thread.\n",
    "     ```python\n",
    "     import threading\n",
    "     import queue\n",
    "\n",
    "     def worker(q):\n",
    "         try:\n",
    "             raise ValueError(\"An error occurred\")\n",
    "         except Exception as e:\n",
    "             q.put(e)\n",
    "\n",
    "     q = queue.Queue()\n",
    "     thread = threading.Thread(target=worker, args=(q,))\n",
    "     thread.start()\n",
    "     thread.join()\n",
    "     \n",
    "     if not q.empty():\n",
    "         print(f\"Exception from thread: {q.get()}\")\n",
    "     ```\n",
    "\n",
    "2. **Exception Handling in Processes:**\n",
    "   - **Try-Except Blocks:** Similar to threads, use try-except blocks in the target function of a process.\n",
    "     ```python\n",
    "     from multiprocessing import Process\n",
    "\n",
    "     def process_function():\n",
    "         try:\n",
    "             pass\n",
    "         except Exception as e:\n",
    "             print(f\"Exception in process: {e}\")\n",
    "\n",
    "     process = Process(target=process_function)\n",
    "     process.start()\n",
    "     process.join()\n",
    "     ```\n",
    "\n",
    "   - **Process Communication:** Use `multiprocessing.Queue` or `multiprocessing.Pipe` to send exception information from child processes back to the main process.\n",
    "     ```python\n",
    "     from multiprocessing import Process, Queue\n",
    "\n",
    "     def worker(queue):\n",
    "         try:\n",
    "             raise ValueError(\"An error occurred\")\n",
    "         except Exception as e:\n",
    "             queue.put(e)\n",
    "\n",
    "     queue = Queue()\n",
    "     process = Process(target=worker, args=(queue,))\n",
    "     process.start()\n",
    "     process.join()\n",
    "     \n",
    "     if not queue.empty():\n",
    "         print(f\"Exception from process: {queue.get()}\")\n",
    "     ```\n",
    "\n",
    "3. **Using Context Managers:**\n",
    "   - **Description:** Context managers (`with` statements) are used to ensure that resources are properly managed, even if an exception occurs.\n",
    "   - **Usage Example:**\n",
    "     ```python\n",
    "     from threading import Lock\n",
    "\n",
    "     lock = Lock()\n",
    "\n",
    "     def thread_function():\n",
    "         with lock:\n",
    "             try:\n",
    "                 pass\n",
    "             except Exception as e:\n",
    "                 print(f\"Exception in thread: {e}\")\n",
    "     ```\n",
    "\n",
    "4. **Exception Aggregation and Handling:**\n",
    "   - **Description:** In more complex scenarios, you might need to aggregate exceptions from multiple threads or processes and handle them in a centralized manner.\n",
    "   - **Example:**\n",
    "     ```python\n",
    "     import threading\n",
    "     import queue\n",
    "\n",
    "     def worker(q):\n",
    "         try:\n",
    "             raise ValueError(\"An error occurred\")\n",
    "         except Exception as e:\n",
    "             q.put(e)\n",
    "\n",
    "     exception_queue = queue.Queue()\n",
    "     threads = [threading.Thread(target=worker, args=(exception_queue,)) for _ in range(5)]\n",
    "\n",
    "     for t in threads:\n",
    "         t.start()\n",
    "     for t in threads:\n",
    "         t.join()\n",
    "\n",
    "     while not exception_queue.empty():\n",
    "         print(f\"Exception from thread: {exception_queue.get()}\")\n",
    "     ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 466,
     "status": "ok",
     "timestamp": 1726100928476,
     "user": {
      "displayName": "Shazil Parwez",
      "userId": "17294264299167245854"
     },
     "user_tz": -330
    },
    "id": "Npv74OG4j_fi",
    "outputId": "fb54820e-3864-462e-d6f8-4b56a9d0d2e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of 4 is 24\n",
      "Factorial of 10 is 3628800\n",
      "Factorial of 5 is 120\n",
      "Factorial of 2 is 2\n",
      "Factorial of 3 is 6\n",
      "Factorial of 6 is 720\n",
      "Factorial of 1 is 1\n",
      "Factorial of 8 is 40320\n",
      "Factorial of 9 is 362880\n",
      "Factorial of 7 is 5040\n"
     ]
    }
   ],
   "source": [
    "#7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. Use concurrent.futures.ThreadPoolExecutor to manage the threads.\n",
    "\n",
    "#Answer 7:\n",
    "\n",
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "def factorial(n):\n",
    "    return math.factorial(n)\n",
    "\n",
    "def main():\n",
    "    numbers = list(range(1, 11))\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(factorial, num): num for num in numbers}\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            num = futures[future]\n",
    "            try:\n",
    "                result = future.result()\n",
    "                print(f'Factorial of {num} is {result}')\n",
    "            except Exception as e:\n",
    "                print(f'Error computing factorial for {num}: {e}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1726100980864,
     "user": {
      "displayName": "Shazil Parwez",
      "userId": "17294264299167245854"
     },
     "user_tz": -330
    },
    "id": "pKNbVYgInzXX",
    "outputId": "579fba8b-235b-4664-dd4f-4d536713fc84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with pool size: 2\n",
      "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "Time taken with pool size 2: 0.0253 seconds\n",
      "\n",
      "Testing with pool size: 4\n",
      "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "Time taken with pool size 4: 0.0439 seconds\n",
      "\n",
      "Testing with pool size: 8\n",
      "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "Time taken with pool size 8: 0.0709 seconds\n"
     ]
    }
   ],
   "source": [
    "#8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 processes).\n",
    "\n",
    "#Answer 8:\n",
    "\n",
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def square(n):\n",
    "    return n * n\n",
    "\n",
    "def main():\n",
    "    numbers = list(range(1, 11))\n",
    "    pool_sizes = [2, 4, 8]\n",
    "\n",
    "    for pool_size in pool_sizes:\n",
    "        print(f'\\nTesting with pool size: {pool_size}')\n",
    "        start_time = time.time()\n",
    "\n",
    "        with multiprocessing.Pool(processes=pool_size) as pool:\n",
    "            results = pool.map(square, numbers)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        print(f'Results: {results}')\n",
    "        print(f'Time taken with pool size {pool_size}: {elapsed_time:.4f} seconds')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjChOYRnoVwI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQt/tzGBDCc4pKqW6nh44I",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
